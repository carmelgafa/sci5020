\relax 
\citation{mahmud2013will}
\@writefile{toc}{\contentsline {section}{\numberline {1}Question 1}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Give reference to a publication in which the exponential distribution has been used in practise. Explain the context in which this distribution has been used in this publication.}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}State the mean and the variance of $X$.}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3} Derive the moment estimator of $\lambda $.}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Use the second moment to obtain another estimator of $\lambda $}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Comment on the unbiasedness and consistency of the moment estimator for $\lambda $ derived in Q1iii. State any assumption/s that need to be made to check for unbiasedness and consistency.}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Unbiasedness:}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Consistency:}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Use R software to generate 1000 data points from an exponential distributed random variable using any admissible parameter value for $\lambda $}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Exponential distributed random variable; histogram of 1000 generated points and theoretical distribution}}{6}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:img-1-6-1}{{1}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.1}Write down the log-likelihood function for this exponentially distributed random variable.}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.2}Evaluate the log-likelihood function for the generated data as a function of $\lambda $, and plot the resulting log-likelihood function against different values of $\lambda $. Present the plot together with the answers.}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Log-likelihood plot for an exponential distribution with varying $\lambda $}}{8}{}\protected@file@percent }
\newlabel{fig:img-1-6-2}{{2}{8}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.6.3}Using the plot or otherwise, which estimate for $\lambda $ is the MLE? Give a reason for your answer.}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}title}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}title}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Question 4 - Jackknife and bootstrap}{9}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces Non linear regression code in R}}{10}{}\protected@file@percent }
\newlabel{lst:nls}{{1}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Nonlinear regression fit: observed vs. predicted values}}{11}{}\protected@file@percent }
\newlabel{fig:img-4-1}{{3}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Construct a computer code in R to find the Jackknife and Bootstrap estimators of $a$ and $b$. In the case of Jackknife, section randomly the sampling into 5 partitions of size 10. In the case of Bootstrap, generate 1000 samples of size 100 with replacement. }{11}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}{\ignorespaces Jackknife resampling code in R}}{13}{}\protected@file@percent }
\newlabel{lst:jk}{{2}{13}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Nonlinear regression fit: observed vs. predicted values including Jackknife predictions}}{14}{}\protected@file@percent }
\newlabel{fig:img-4-1-1}{{4}{14}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}{\ignorespaces Bootstrap resampling code in R}}{16}{}\protected@file@percent }
\newlabel{lst:bs}{{3}{16}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Nonlinear regression fit: observed vs. predicted values including Jackknife and Bootstrap predictions}}{17}{}\protected@file@percent }
\newlabel{fig:img-4-1-2}{{5}{17}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}For the Jackknife estimator, find a 95\% confidence interval using the normal distribution and the t-distribution. For the Bootstrap estimator, find a 95\% normal, t and empirical confidence intervals.}{17}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Confidence Intervals for Parameters $a$ and $b$ Using Jackknife and Bootstrap Methods}}{18}{}\protected@file@percent }
\newlabel{tab:ci_results}{{1}{18}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Question 5 â€“ The EM Algorithm }{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Simulate 1000 readings from a mixture Gaussian distribution with 3 or more Gaussians.}{19}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}{\ignorespaces Gaussian mixture sample generation code in R}}{20}{}\protected@file@percent }
\newlabel{lst:gausmix}{{4}{20}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}{\ignorespaces Generation of data for this question}}{21}{}\protected@file@percent }
\newlabel{lst:gem-gausmix}{{5}{21}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Distribution of generated data}}{21}{}\protected@file@percent }
\newlabel{fig:img-5-1}{{6}{21}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Determine initial values $\mu _1^{(0)}, \dots  , \mu _K^{(0)}, \sigma _1^{(0)}, \dots  , \sigma _K^{(0)}, \pi _1^{(0)}, \dots  , \pi _K^{(0)}$ using a K-means clustering approach or otherwise. }{22}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}{\ignorespaces k-means algorithm to compute the initial values of the mixed Gaussian model parameters}}{23}{}\protected@file@percent }
\newlabel{lst:kmeans}{{6}{23}{}{}{}}
\bibdata{references}
\bibcite{mahmud2013will}{1}
\bibstyle{plain}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Estimated parameters for the initial values of Gaussian mixture model}}{24}{}\protected@file@percent }
\newlabel{tab:gmm_parameters}{{2}{24}{}{}{}}
\gdef \@abspage@last{24}
